{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch_sparse import matmul, fill_diag\n",
    "from torch_sparse import sum as sparsesum\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_geometric.datasets import Reddit2\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import NeighborSampler, ClusterLoader\n",
    "from torch_geometric.nn import Linear, GCNConv\n",
    "from torch_geometric.loader import ClusterData\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "\n",
    "to_sparse = T.ToSparseTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "outputs": [],
   "source": [
    "path = os.environ.get('DATA_DIR')\n",
    "path = os.path.join(path, 'ogb')\n",
    "transform = T.Compose([T.ToSparseTensor()])\n",
    "dataset = PygNodePropPredDataset(name='ogbn-products', root=path, transform=transform)\n",
    "\n",
    "world_size = torch.cuda.device_count()\n",
    "num_classes = dataset.num_classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cluster_data = ClusterData(dataset[0], num_parts=world_size, recursive=False,\n",
    "                           save_dir=dataset.processed_dir)\n",
    "data_list = list(ClusterLoader(cluster_data, batch_size=1, shuffle=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing METIS partitioning with 4 parts... Done! [15.65s]\n",
      "Permuting data... Done! [27.85s]\n",
      "Pre-processing subgraphs... Done! [3.54s]\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric_autoscale import metis, permute, SubgraphLoader\n",
    "\n",
    "data = dataset[0]\n",
    "perm, ptr = metis(data.adj_t, world_size, log=True)\n",
    "data = permute(data, perm, log=True)\n",
    "data_list = list(SubgraphLoader(data, ptr, batch_size=1, shuffle=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613761\n",
      "814388\n",
      "\n",
      "622604\n",
      "814385\n",
      "\n",
      "601931\n",
      "882541\n",
      "\n",
      "610733\n",
      "903601\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sub_data in data_list:\n",
    "    print(sub_data.batch_size)\n",
    "    print(sub_data.data.num_nodes)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([613761, 622604, 601931, 610733])"
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptr[1:] - ptr[:-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 677613, 1052124, 1937103,  ..., 1973056, 1305320, 1309691])"
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_data = data_list[0]\n",
    "batch_size = sub_data.batch_size\n",
    "n_id = sub_data.n_id\n",
    "\n",
    "# torch.equal(sub_data.data.x[batch_size:], data.x[n_id[batch_size:]])\n",
    "\n",
    "out_of_batch = sub_data.n_id[sub_data.batch_size:]\n",
    "out_of_batch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "outputs": [
    {
     "data": {
      "text/plain": "[83025, 75734, 160531, 167743]"
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.utils import mask_to_index\n",
    "\n",
    "halo_nodes = [[[] for j in range(world_size)] for i in range(world_size)]\n",
    "reverse_idx = [[] for _ in range(world_size)]\n",
    "halo_counts = [[] for _ in range(world_size)]\n",
    "\n",
    "package_sizes = []\n",
    "for batch_id, sub_data in enumerate(data_list):\n",
    "    out_of_batch = sub_data.n_id[sub_data.batch_size:]\n",
    "\n",
    "    package_size = 0\n",
    "    for i in range(world_size):\n",
    "        if batch_id == i:\n",
    "            continue\n",
    "        mask = (out_of_batch >= ptr[i]) & (out_of_batch < ptr[i+1])\n",
    "        num_halos = mask.sum().item()\n",
    "        if num_halos > package_size:\n",
    "            package_size = num_halos\n",
    "\n",
    "        halo_nodes[i][batch_id] = out_of_batch[mask] - ptr[i]\n",
    "        reverse_idx[batch_id].append(mask_to_index(mask))\n",
    "        halo_counts[batch_id].append(num_halos)\n",
    "    package_sizes.append(package_size)\n",
    "package_sizes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "package_size = 80000\n",
    "temp = data_list[0].data.x[halo_nodes[0][1]]\n",
    "temp_ = F.pad(temp, (0, 0, 0, package_size-temp.size(0)))\n",
    "temp_[:temp.size(0)].equal(temp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([200627, 100])"
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather, root node is 0\n",
    "scattered_nodes = torch.cat([data_list[i].data.x[halo_nodes[i][0]] for i in range(1, world_size)])\n",
    "scattered_nodes.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(scattered_nodes, data_list[0].data.x[batch_size:][torch.cat(reverse_idx[0])])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = torch.ones_like(data_list[0].data.x[batch_size:])\n",
    "# 更新当前层halo-node表征：data.x[batch_size:][torch.cat(reverse_idx[0])] = scattered_nodes\n",
    "temp[torch.cat(reverse_idx[0])] = scattered_nodes\n",
    "temp.equal(data_list[0].data.x[batch_size:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}